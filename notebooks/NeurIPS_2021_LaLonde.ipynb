{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import numpy as np\r\n",
    "import scipy.stats\r\n",
    "import scipy.linalg\r\n",
    "import itertools\r\n",
    "import pandas \n",
    "import seaborn as snsas pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading LaLonde Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cps1 = pd.read_stata('https://users.nber.org/~rdehejia/data/cps_controls.dta')\r\n",
    "df_cps3 = pd.read_stata('https://users.nber.org/~rdehejia/data/cps_controls3.dta')\r\n",
    "df_nsw = pd.read_stata('https://users.nber.org/~rdehejia/data/nsw_dw.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NSW Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_nsw\n",
    "X = np.array(df[\"treat\"].values.tolist())\n",
    "Yflag = (df[\"re78\"] > df[\"re75\"])\n",
    "Y = np.array((Yflag*1).values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>treat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>married</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>re74</th>\n",
       "      <th>re75</th>\n",
       "      <th>re78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9930.045898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3595.894043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24909.449219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7506.145996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>289.789886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31886.429688</td>\n",
       "      <td>12357.219727</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17491.449219</td>\n",
       "      <td>13371.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9594.307617</td>\n",
       "      <td>16341.160156</td>\n",
       "      <td>16900.300781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24731.619141</td>\n",
       "      <td>16946.630859</td>\n",
       "      <td>7343.963867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25720.919922</td>\n",
       "      <td>23031.980469</td>\n",
       "      <td>5448.800781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>445 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  data_id  treat   age  education  black  hispanic  married  \\\n",
       "0    Dehejia-Wahba Sample    1.0  37.0       11.0    1.0       0.0      1.0   \n",
       "1    Dehejia-Wahba Sample    1.0  22.0        9.0    0.0       1.0      0.0   \n",
       "2    Dehejia-Wahba Sample    1.0  30.0       12.0    1.0       0.0      0.0   \n",
       "3    Dehejia-Wahba Sample    1.0  27.0       11.0    1.0       0.0      0.0   \n",
       "4    Dehejia-Wahba Sample    1.0  33.0        8.0    1.0       0.0      0.0   \n",
       "..                    ...    ...   ...        ...    ...       ...      ...   \n",
       "440  Dehejia-Wahba Sample    0.0  21.0        9.0    1.0       0.0      0.0   \n",
       "441  Dehejia-Wahba Sample    0.0  28.0       11.0    1.0       0.0      0.0   \n",
       "442  Dehejia-Wahba Sample    0.0  29.0        9.0    0.0       1.0      0.0   \n",
       "443  Dehejia-Wahba Sample    0.0  25.0        9.0    1.0       0.0      1.0   \n",
       "444  Dehejia-Wahba Sample    0.0  22.0       10.0    0.0       0.0      1.0   \n",
       "\n",
       "     nodegree          re74          re75          re78  \n",
       "0         1.0      0.000000      0.000000   9930.045898  \n",
       "1         1.0      0.000000      0.000000   3595.894043  \n",
       "2         0.0      0.000000      0.000000  24909.449219  \n",
       "3         1.0      0.000000      0.000000   7506.145996  \n",
       "4         1.0      0.000000      0.000000    289.789886  \n",
       "..        ...           ...           ...           ...  \n",
       "440       1.0  31886.429688  12357.219727      0.000000  \n",
       "441       1.0  17491.449219  13371.250000      0.000000  \n",
       "442       1.0   9594.307617  16341.160156  16900.300781  \n",
       "443       1.0  24731.619141  16946.630859   7343.963867  \n",
       "444       1.0  25720.919922  23031.980469   5448.800781  \n",
       "\n",
       "[445 rows x 11 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing re74 or no degree\n",
    "Z = np.array([0] * df.shape[0])\n",
    "for i in range(df.shape[0]):\n",
    "    if ((df[\"re75\"][i] == 0) and (df[\"married\"][i] == 0)):\n",
    "        Z[i] = 3\n",
    "    elif ((df[\"re75\"][i] == 0) and (df[\"married\"][i] > 0)):\n",
    "        Z[i] = 2\n",
    "    elif ((df[\"re75\"][i] > 0) and (df[\"married\"][i] == 0)):\n",
    "        Z[i] = 1\n",
    "    elif ((df[\"re75\"][i] > 0) and (df[\"married\"][i] > 0)):\n",
    "        Z[i] = 0\n",
    "        \n",
    "# Strata by age\n",
    "W = np.array([0] * df.shape[0])\n",
    "for i in range(df.shape[0]):\n",
    "    if df[\"age\"][i] >= df[\"age\"].quantile(0.9):\n",
    "        W[i] = 3\n",
    "    elif (df[\"age\"][i] >= df[\"age\"].quantile(0.7)) and (df[\"age\"][i] < df[\"age\"].quantile(0.9)):\n",
    "        W[i] = 2\n",
    "    elif (df[\"age\"][i] >= df[\"age\"].quantile(0.25)) and (df[\"age\"][i] < df[\"age\"].quantile(0.7)):\n",
    "        W[i] = 1\n",
    "    elif (df[\"age\"][i] >= df[\"age\"].quantile(0)) and (df[\"age\"][i] < df[\"age\"].quantile(0.25)):\n",
    "        W[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing re74 or no degree\n",
    "Z = np.array([0] * df.shape[0])\n",
    "for i in range(df.shape[0]):\n",
    "    if ((df[\"nodegree\"][i] == 0) and (df[\"married\"][i] == 0)):\n",
    "        Z[i] = 3\n",
    "    elif ((df[\"nodegree\"][i] == 0) and (df[\"married\"][i] > 0)):\n",
    "        Z[i] = 2\n",
    "    elif ((df[\"nodegree\"][i] > 0) and (df[\"married\"][i] == 0)):\n",
    "        Z[i] = 1\n",
    "    elif ((df[\"nodegree\"][i] > 0) and (df[\"married\"][i] > 0)):\n",
    "        Z[i] = 0\n",
    "        \n",
    "# Strata by age\n",
    "W = np.array([0] * df.shape[0])\n",
    "for i in range(df.shape[0]):\n",
    "    if df[\"age\"][i] >= df[\"age\"].quantile(0.9):\n",
    "        W[i] = 3\n",
    "    elif (df[\"age\"][i] >= df[\"age\"].quantile(0.7)) and (df[\"age\"][i] < df[\"age\"].quantile(0.9)):\n",
    "        W[i] = 2\n",
    "    elif (df[\"age\"][i] >= df[\"age\"].quantile(0.25)) and (df[\"age\"][i] < df[\"age\"].quantile(0.7)):\n",
    "        W[i] = 1\n",
    "    elif (df[\"age\"][i] >= df[\"age\"].quantile(0)) and (df[\"age\"][i] < df[\"age\"].quantile(0.25)):\n",
    "        W[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>treat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>married</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>re74</th>\n",
       "      <th>re75</th>\n",
       "      <th>re78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9930.045898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3595.894043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24909.449219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7506.145996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>289.789886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31886.429688</td>\n",
       "      <td>12357.219727</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17491.449219</td>\n",
       "      <td>13371.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9594.307617</td>\n",
       "      <td>16341.160156</td>\n",
       "      <td>16900.300781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24731.619141</td>\n",
       "      <td>16946.630859</td>\n",
       "      <td>7343.963867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25720.919922</td>\n",
       "      <td>23031.980469</td>\n",
       "      <td>5448.800781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>445 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  data_id  treat   age  education  black  hispanic  married  \\\n",
       "0    Dehejia-Wahba Sample    1.0  37.0       11.0    1.0       0.0      1.0   \n",
       "1    Dehejia-Wahba Sample    1.0  22.0        9.0    0.0       1.0      0.0   \n",
       "2    Dehejia-Wahba Sample    1.0  30.0       12.0    1.0       0.0      0.0   \n",
       "3    Dehejia-Wahba Sample    1.0  27.0       11.0    1.0       0.0      0.0   \n",
       "4    Dehejia-Wahba Sample    1.0  33.0        8.0    1.0       0.0      0.0   \n",
       "..                    ...    ...   ...        ...    ...       ...      ...   \n",
       "440  Dehejia-Wahba Sample    0.0  21.0        9.0    1.0       0.0      0.0   \n",
       "441  Dehejia-Wahba Sample    0.0  28.0       11.0    1.0       0.0      0.0   \n",
       "442  Dehejia-Wahba Sample    0.0  29.0        9.0    0.0       1.0      0.0   \n",
       "443  Dehejia-Wahba Sample    0.0  25.0        9.0    1.0       0.0      1.0   \n",
       "444  Dehejia-Wahba Sample    0.0  22.0       10.0    0.0       0.0      1.0   \n",
       "\n",
       "     nodegree          re74          re75          re78  \n",
       "0         1.0      0.000000      0.000000   9930.045898  \n",
       "1         1.0      0.000000      0.000000   3595.894043  \n",
       "2         0.0      0.000000      0.000000  24909.449219  \n",
       "3         1.0      0.000000      0.000000   7506.145996  \n",
       "4         1.0      0.000000      0.000000    289.789886  \n",
       "..        ...           ...           ...           ...  \n",
       "440       1.0  31886.429688  12357.219727      0.000000  \n",
       "441       1.0  17491.449219  13371.250000      0.000000  \n",
       "442       1.0   9594.307617  16341.160156  16900.300781  \n",
       "443       1.0  24731.619141  16946.630859   7343.963867  \n",
       "444       1.0  25720.919922  23031.980469   5448.800781  \n",
       "\n",
       "[445 rows x 11 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating P1, P0, Q1, and Q0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_PQ(X,Y,Z,W):\r\n",
    "    phat_z0x1 = (np.sum((Z==0) & (X==1))/np.sum(X==1))\r\n",
    "    phat_z1x1 = (np.sum((Z==1) & (X==1))/np.sum(X==1))\r\n",
    "    phat_z2x1 = (np.sum((Z==2) & (X==1))/np.sum(X==1))\r\n",
    "    phat_z3x1 = (np.sum((Z==3) & (X==1))/np.sum(X==1))\r\n",
    "    phat_z0x0 = (np.sum((Z==0) & (X==0))/(np.sum(X==0)))\r\n",
    "    phat_z1x0 = (np.sum((Z==1) & (X==0))/(np.sum(X==0)))\r\n",
    "    phat_z2x0 = (np.sum((Z==2) & (X==0))/(np.sum(X==0)))\r\n",
    "    phat_z3x0 = (np.sum((Z==3) & (X==0))/(np.sum(X==0)))\r\n",
    "    phat_w0x1 = (np.sum((W==0) & (X==1))/np.sum(X==1))\r\n",
    "    phat_w1x1 = (np.sum((W==1) & (X==1))/np.sum(X==1))\r\n",
    "    phat_w2x1 = (np.sum((W==2) & (X==1))/np.sum(X==1))\r\n",
    "    phat_w3x1 = (np.sum((W==3) & (X==1))/np.sum(X==1))\r\n",
    "    phat_w0x0 = (np.sum((W==0) & (X==0))/(np.sum(X==0)))\r\n",
    "    phat_w1x0 = (np.sum((W==1) & (X==0))/(np.sum(X==0)))\r\n",
    "    phat_w2x0 = (np.sum((W==2) & (X==0))/(np.sum(X==0)))\r\n",
    "    phat_w3x0 = (np.sum((W==3) & (X==0))/(np.sum(X==0)))\r\n",
    "    phat_z0w0x1 = np.sum((Z==0) & (W==0) & (X==1))/np.sum(X==1)\r\n",
    "    phat_z0w1x1 = np.sum((Z==0) & (W==1) & (X==1))/np.sum(X==1)\r\n",
    "    phat_z0w2x1 = np.sum((Z==0) & (W==2) & (X==1))/np.sum(X==1)\r\n",
    "    phat_z0w3x1 = np.sum((Z==0) & (W==3) & (X==1))/np.sum(X==1)\r\n",
    "    phat_z0w0x0 = np.sum((Z==0) & (W==0) & (X==0))/(np.sum(X==0))\r\n",
    "    phat_z0w1x0 = np.sum((Z==0) & (W==1) & (X==0))/(np.sum(X==0))\r\n",
    "    phat_z0w2x0 = np.sum((Z==0) & (W==2) & (X==0))/(np.sum(X==0))\r\n",
    "    phat_z0w3x0 = np.sum((Z==0) & (W==3) & (X==0))/(np.sum(X==0))\r\n",
    "    phat_z1w0x1 = np.sum((Z==1) & (W==0) & (X==1))/np.sum(X==1)\r\n",
    "    phat_z1w1x1 = np.sum((Z==1) & (W==1) & (X==1))/np.sum(X==1)\r\n",
    "    phat_z1w2x1 = np.sum((Z==1) & (W==2) & (X==1))/np.sum(X==1)\r\n",
    "    phat_z1w3x1 = np.sum((Z==1) & (W==3) & (X==1))/np.sum(X==1)\r\n",
    "    phat_z1w0x0 = np.sum((Z==1) & (W==0) & (X==0))/(np.sum(X==0))\r\n",
    "    phat_z1w1x0 = np.sum((Z==1) & (W==1) & (X==0))/(np.sum(X==0))\r\n",
    "    phat_z1w2x0 = np.sum((Z==1) & (W==2) & (X==0))/(np.sum(X==0))\r\n",
    "    phat_z1w3x0 = np.sum((Z==1) & (W==3) & (X==0))/(np.sum(X==0))\r\n",
    "    phat_z2w0x1 = np.sum((Z==2) & (W==0) & (X==1))/np.sum(X==1)\r\n",
    "    phat_z2w1x1 = np.sum((Z==2) & (W==1) & (X==1))/np.sum(X==1)\r\n",
    "    phat_z2w2x1 = np.sum((Z==2) & (W==2) & (X==1))/np.sum(X==1)\r\n",
    "    phat_z2w3x1 = np.sum((Z==2) & (W==3) & (X==1))/np.sum(X==1)\r\n",
    "    phat_z2w0x0 = np.sum((Z==2) & (W==0) & (X==0))/(np.sum(X==0))\r\n",
    "    phat_z2w1x0 = np.sum((Z==2) & (W==1) & (X==0))/(np.sum(X==0))\r\n",
    "    phat_z2w2x0 = np.sum((Z==2) & (W==2) & (X==0))/(np.sum(X==0))\r\n",
    "    phat_z2w3x0 = np.sum((Z==2) & (W==3) & (X==0))/(np.sum(X==0))\r\n",
    "    phat_z3w0x1 = np.sum((Z==3) & (W==0) & (X==1))/np.sum(X==1)\r\n",
    "    phat_z3w1x1 = np.sum((Z==3) & (W==1) & (X==1))/np.sum(X==1)\r\n",
    "    phat_z3w2x1 = np.sum((Z==3) & (W==2) & (X==1))/np.sum(X==1)\r\n",
    "    phat_z3w3x1 = np.sum((Z==3) & (W==3) & (X==1))/np.sum(X==1)\r\n",
    "    phat_z3w0x0 = np.sum((Z==3) & (W==0) & (X==0))/(np.sum(X==0))\r\n",
    "    phat_z3w1x0 = np.sum((Z==3) & (W==1) & (X==0))/(np.sum(X==0))\r\n",
    "    phat_z3w2x0 = np.sum((Z==3) & (W==2) & (X==0))/(np.sum(X==0))\r\n",
    "    phat_z3w3x0 = np.sum((Z==3) & (W==3) & (X==0))/(np.sum(X==0))\r\n",
    "    phat_y_x1 = (np.sum((Y==1) & (X==1))/np.sum(X==1))\r\n",
    "    phat_y_x0 = (np.sum((Y==1) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz0_x1 = (np.sum((Y==1) & (Z==0) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz1_x1 = (np.sum((Y==1) & (Z==1) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz2_x1 = (np.sum((Y==1) & (Z==2) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz3_x1 = (np.sum((Y==1) & (Z==3) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yw0_x1 = (np.sum((Y==1) & (W==0) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yw1_x1 = (np.sum((Y==1) & (W==1) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yw2_x1 = (np.sum((Y==1) & (W==2) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yw3_x1 = (np.sum((Y==1) & (W==3) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz0_x0 = (np.sum((Y==1) & (Z==0) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz1_x0 = (np.sum((Y==1) & (Z==1) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz2_x0 = (np.sum((Y==1) & (Z==2) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz3_x0 = (np.sum((Y==1) & (Z==3) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yw0_x0 = (np.sum((Y==1) & (W==0) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yw1_x0 = (np.sum((Y==1) & (W==1) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yw2_x0 = (np.sum((Y==1) & (W==2) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yw3_x0 = (np.sum((Y==1) & (W==3) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz0w0_x1 = (np.sum((Y==1) & (Z==0) & (W==0) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz0w1_x1 = (np.sum((Y==1) & (Z==0) & (W==1) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz0w2_x1 = (np.sum((Y==1) & (Z==0) & (W==2) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz0w3_x1 = (np.sum((Y==1) & (Z==0) & (W==3) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz1w0_x1 = (np.sum((Y==1) & (Z==1) & (W==0) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz1w1_x1 = (np.sum((Y==1) & (Z==1) & (W==1) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz1w2_x1 = (np.sum((Y==1) & (Z==1) & (W==2) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz1w3_x1 = (np.sum((Y==1) & (Z==1) & (W==3) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz2w0_x1 = (np.sum((Y==1) & (Z==2) & (W==0) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz2w1_x1 = (np.sum((Y==1) & (Z==2) & (W==1) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz2w2_x1 = (np.sum((Y==1) & (Z==2) & (W==2) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz2w3_x1 = (np.sum((Y==1) & (Z==2) & (W==3) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz3w0_x1 = (np.sum((Y==1) & (Z==3) & (W==0) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz3w1_x1 = (np.sum((Y==1) & (Z==3) & (W==1) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz3w2_x1 = (np.sum((Y==1) & (Z==3) & (W==2) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz3w3_x1 = (np.sum((Y==1) & (Z==3) & (W==3) & (X==1))/np.sum(X==1))\r\n",
    "    phat_yz0w0_x0 = (np.sum((Y==1) & (Z==0) & (W==0) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz0w1_x0 = (np.sum((Y==1) & (Z==0) & (W==1) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz0w2_x0 = (np.sum((Y==1) & (Z==0) & (W==2) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz0w3_x0 = (np.sum((Y==1) & (Z==0) & (W==3) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz1w0_x0 = (np.sum((Y==1) & (Z==1) & (W==0) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz1w1_x0 = (np.sum((Y==1) & (Z==1) & (W==1) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz1w2_x0 = (np.sum((Y==1) & (Z==1) & (W==2) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz1w3_x0 = (np.sum((Y==1) & (Z==1) & (W==3) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz2w0_x0 = (np.sum((Y==1) & (Z==2) & (W==0) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz2w1_x0 = (np.sum((Y==1) & (Z==2) & (W==1) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz2w2_x0 = (np.sum((Y==1) & (Z==2) & (W==2) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz2w3_x0 = (np.sum((Y==1) & (Z==2) & (W==3) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz3w0_x0 = (np.sum((Y==1) & (Z==3) & (W==0) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz3w1_x0 = (np.sum((Y==1) & (Z==3) & (W==1) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz3w2_x0 = (np.sum((Y==1) & (Z==3) & (W==2) & (X==0))/np.sum(X==0))\r\n",
    "    phat_yz3w3_x0 = (np.sum((Y==1) & (Z==3) & (W==3) & (X==0))/np.sum(X==0))\r\n",
    "    phat_x1 = np.sum(X==1)/X.shape[0]\r\n",
    "    phat_x0 = np.sum(X==0)/X.shape[0]\r\n",
    "\r\n",
    "    ### Calculating P1, P0, Q1, Q0\r\n",
    "    Phat1 = np.array([[1, phat_z0x1, phat_z1x1, phat_z2x1],\r\n",
    "                     [phat_w0x1, phat_z0w0x1, phat_z1w0x1, phat_z2w0x1],\r\n",
    "                     [phat_w1x1, phat_z0w1x1, phat_z1w1x1, phat_z2w1x1],\r\n",
    "                     [phat_w2x1, phat_z0w2x1, phat_z1w2x1, phat_z2w2x1]])\r\n",
    "    Phat0 = np.array([[1, phat_z0x0, phat_z1x0, phat_z2x0],\r\n",
    "                     [phat_w0x0, phat_z0w0x0, phat_z1w0x0, phat_z2w0x0],\r\n",
    "                     [phat_w1x0, phat_z0w1x0, phat_z1w1x0, phat_z2w1x0],\r\n",
    "                     [phat_w2x0, phat_z0w2x0, phat_z1w2x0, phat_z2w2x0]])\r\n",
    "    Qhat1 = np.array([[phat_y_x1, phat_yz0_x1, phat_yz1_x1, phat_yz2_x1],\r\n",
    "                      [phat_yw0_x1, phat_yz0w0_x1, phat_yz1w0_x1, phat_yz2w0_x1],\r\n",
    "                      [phat_yw1_x1, phat_yz0w1_x1, phat_yz1w1_x1, phat_yz2w1_x1],\r\n",
    "                      [phat_yw2_x1, phat_yz0w2_x1, phat_yz1w2_x1, phat_yz2w2_x1]])\r\n",
    "    Qhat0 = np.array([[phat_y_x0, phat_yz0_x0, phat_yz1_x0, phat_yz2_x0],\r\n",
    "                      [phat_yw0_x0, phat_yz0w0_x0, phat_yz1w0_x0, phat_yz2w0_x0],\r\n",
    "                      [phat_yw1_x0, phat_yz0w1_x0, phat_yz1w1_x0, phat_yz2w1_x0],\r\n",
    "                      [phat_yw2_x0, phat_yz0w2_x0, phat_yz1w2_x0, phat_yz2w2_x0]])\r\n",
    "\r\n",
    "    return Phat1, Phat0, Qhat1, Qhat0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "Phat1, Phat0, Qhat1, Qhat0 = calculate_PQ(X,Y,Z,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.581, 0.046, 0.446, 0.023],\n",
       "       [0.177, 0.008, 0.169, 0.   ],\n",
       "       [0.223, 0.019, 0.177, 0.004],\n",
       "       [0.135, 0.015, 0.062, 0.015]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qhat0.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating joint distribution of potential outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_perm1(S, P1, P0, Q1, Q0):\r\n",
    "    P1 = torch.from_numpy(P1.astype(np.float32)).clone()\r\n",
    "    P0 = torch.from_numpy(P0.astype(np.float32)).clone()\r\n",
    "    Q1 = torch.from_numpy(Q1.astype(np.float32)).clone()\r\n",
    "    Q0 = torch.from_numpy(Q0.astype(np.float32)).clone()\r\n",
    "\r\n",
    "    PQ1 = np.dot(np.linalg.inv(P1), Q1)\r\n",
    "    PQ1 = torch.from_numpy(PQ1.astype(np.float32)).clone()\r\n",
    "    PQ0 = np.dot(np.linalg.inv(P0), Q0)\r\n",
    "    PQ0 = torch.from_numpy(PQ0.astype(np.float32)).clone()\r\n",
    "\r\n",
    "    Mx1 = np.array(\r\n",
    "        [[1,0,0,0],\r\n",
    "         [0,1,0,0],\r\n",
    "         [0,0,0,0],\r\n",
    "         [0,0,0,0]]\r\n",
    "    )\r\n",
    "    Mx0 = np.array(\r\n",
    "        [[1,0,0,0],\r\n",
    "         [0,0,0,0],\r\n",
    "         [0,0,1,0],\r\n",
    "         [0,0,0,0]]\r\n",
    "    )\r\n",
    "    Mx1 = torch.from_numpy(Mx1.astype(np.float32)).clone()\r\n",
    "    Mx0 = torch.from_numpy(Mx0.astype(np.float32)).clone()\r\n",
    "\r\n",
    "    diag1 = torch.mm(torch.mm(S, PQ1), torch.inverse(S))\r\n",
    "    diag0 = torch.mm(torch.mm(S, PQ0), torch.inverse(S))\r\n",
    "        \r\n",
    "    loss = (\r\n",
    "            torch.norm(diag1 - Mx1)**2 + torch.norm(diag0 - Mx0)**2\r\n",
    "    )\r\n",
    "    u1 = torch.mm(P1, torch.inverse(S))[0,:]\r\n",
    "    u0 = torch.mm(P0, torch.inverse(S))[0,:]\r\n",
    "\r\n",
    "    return loss,u1,u0,diag1,diag0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commutabilitycheck(P1,P0,Q1,Q0):\r\n",
    "    PQ1 = np.dot(np.linalg.inv(P1), Q1)\r\n",
    "    PQ0 = np.dot(np.linalg.inv(P0), Q0)\r\n",
    "    return np.linalg.norm(np.dot(PQ1, PQ0)-np.dot(PQ0,PQ1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim(P1, P0, Q1, Q0, phat_x1, phat_x0, learning_rate = 1e-5, seed = None, maxiter=20000, rho=0.5):\r\n",
    "    P1 = torch.from_numpy(P1.astype(np.float32)).clone()\r\n",
    "    P0 = torch.from_numpy(P0.astype(np.float32)).clone()\r\n",
    "    Q1 = torch.from_numpy(Q1.astype(np.float32)).clone()\r\n",
    "    Q0 = torch.from_numpy(Q0.astype(np.float32)).clone()\r\n",
    "\r\n",
    "    PQ1 = np.dot(np.linalg.inv(P1), Q1)\r\n",
    "    PQ1 = torch.from_numpy(PQ1.astype(np.float32)).clone()\r\n",
    "    PQ0 = np.dot(np.linalg.inv(P0), Q0)\r\n",
    "    PQ0 = torch.from_numpy(PQ0.astype(np.float32)).clone()\r\n",
    "    print(\"Commutability check:\", commutabilitycheck(P1,P0,Q1,Q0))\r\n",
    "    \r\n",
    "    Mx1 = np.array(\r\n",
    "        [[1,0,0,0],\r\n",
    "         [0,1,0,0],\r\n",
    "         [0,0,0,0],\r\n",
    "         [0,0,0,0]]\r\n",
    "    )\r\n",
    "    Mx0 = np.array(\r\n",
    "        [[1,0,0,0],\r\n",
    "         [0,0,0,0],\r\n",
    "         [0,0,1,0],\r\n",
    "         [0,0,0,0]]\r\n",
    "    )\r\n",
    "    Mx1 = torch.from_numpy(Mx1.astype(np.float32)).clone()\r\n",
    "    Mx0 = torch.from_numpy(Mx0.astype(np.float32)).clone()\r\n",
    "    \r\n",
    "    r1 = r0 = rho\r\n",
    "    lambdavec1 = torch.zeros(4)\r\n",
    "    lambdavec0  = torch.zeros(4)\r\n",
    "    \r\n",
    "    # Randomly initialize estimates\r\n",
    "    if seed is not None:\r\n",
    "        np.random.seed(seed)  \r\n",
    "        torch.manual_seed(seed)      \r\n",
    "    S = np.random.rand(4, 3)\r\n",
    "    for i in range(4):\r\n",
    "        for j in range(3):\r\n",
    "            S[i,j] = (1 - S[i,:j].sum()) * np.random.rand(1)\r\n",
    "    S = torch.from_numpy(S.astype(np.float32)).clone()\r\n",
    "    S.requires_grad = True\r\n",
    "    \r\n",
    "    u1 = torch.mm(P1, torch.inverse(torch.cat([torch.ones(4,1),S], dim=1)))[0,:]\r\n",
    "    u0 = torch.mm(P0, torch.inverse(torch.cat([torch.ones(4,1),S], dim=1)))[0,:]\r\n",
    "    \r\n",
    "    losslist = np.array([])\r\n",
    "    for t in range(maxiter):\r\n",
    "        diag1 = torch.mm(torch.mm(torch.cat([torch.ones(4,1),S], dim=1), PQ1), \r\n",
    "                         torch.inverse(torch.cat([torch.ones(4,1),S], dim=1)))\r\n",
    "        diag0 = torch.mm(torch.mm(torch.cat([torch.ones(4,1),S], dim=1), PQ0), \r\n",
    "                         torch.inverse(torch.cat([torch.ones(4,1),S], dim=1)))\r\n",
    "        u1 = torch.clamp(torch.mm(P1, torch.inverse(torch.cat([torch.ones(4,1),S], dim=1)))[0,:], max=1, min=1e-4)\r\n",
    "        u0 = torch.clamp(torch.mm(P0, torch.inverse(torch.cat([torch.ones(4,1),S], dim=1)))[0,:], max=1, min=1e-4)\r\n",
    "\r\n",
    "        f = torch.zeros(6)\r\n",
    "        if torch.any((lambdavec1 + rho * (u1 - 1)) > 1):\r\n",
    "            f1a = (\r\n",
    "                (lambdavec1 * (u1 - 1))[(lambdavec1 + rho * (u1 - 1)) > 1] \r\n",
    "                + (rho/2) * torch.linalg.norm(u1[(lambdavec1 + rho * (u1 - 1)) > 1] - 1)**2\r\n",
    "                  )\r\n",
    "            f[0] = torch.sum(f1a)\r\n",
    "        elif torch.any(lambdavec1 + rho * u1 < 1):\r\n",
    "            f1b = (\r\n",
    "                (lambdavec1 * u1)[(lambdavec1 + rho * u1) < 1] +\r\n",
    "                (rho/2) * torch.linalg.norm(u1[(lambdavec1 + rho * u1) < 1])**2)\r\n",
    "            f[1] = torch.sum(f1b)\r\n",
    "        elif not (torch.any((lambdavec1 + rho * (u1 - 1)) > 1) or torch.any(lambdavec1 + rho * u1 < 1)):\r\n",
    "            f1c = (- lambdavec1[not (any((lambdavec1 + rho * (u1 - 1)) > 1) or any((lambdavec1 + rho * u1) < 1))]**2 / (2*rho))\r\n",
    "            f[2] = torch.sum(f1c)\r\n",
    "\r\n",
    "        if torch.any((lambdavec0 + rho * (u0 - 1)) > 1):\r\n",
    "            f0a = ((lambdavec0 * (u0 - 1))[(lambdavec0 + rho * (u0 - 1)) > 1] \r\n",
    "                + (rho/2) * torch.linalg.norm(u0[(lambdavec0 + rho * (u0 - 1)) > 1] - 1)**2)\r\n",
    "            f[3] = torch.sum(f0a)\r\n",
    "        elif torch.any((lambdavec0 + rho * u0) < 1):\r\n",
    "            f0b = ((lambdavec0 * u0)[(lambdavec0 + rho * u0) < 1] \r\n",
    "                + (rho/2) * torch.linalg.norm(u0[(lambdavec0 + rho * u0) < 1])**2)\r\n",
    "            f[4] = torch.sum(f0b)\r\n",
    "        elif not (torch.any((lambdavec0 + rho * (u0 - 1)) > 1) or torch.any(lambdavec0 + rho * u0 < 1)):\r\n",
    "            f0c = (- lambdavec0[not (any((lambdavec0 + rho * (u0 - 1)) > 1) or any((lambdavec0 + rho * u0) < 1))]**2 / (2*rho))\r\n",
    "            f[5] = torch.sum(f0c)\r\n",
    "        \r\n",
    "        loss = (\r\n",
    "            torch.norm(diag1 - Mx1) + torch.norm(diag0 - Mx0)\r\n",
    "            + r1 * (torch.dot(torch.ones(4), u1) - 1) + rho/2  * (torch.dot(torch.ones(4), u1) - 1)**2\r\n",
    "            + r0 * (torch.dot(torch.ones(4), u0) - 1) + rho/2  * (torch.dot(torch.ones(4), u0) - 1)**2\r\n",
    "            + torch.sum(f)\r\n",
    "        )\r\n",
    "        loss.backward()\r\n",
    "\r\n",
    "        with torch.no_grad():\r\n",
    "            for i in range(4):\r\n",
    "                for j in range(3):\r\n",
    "                    S[i,j] = torch.clamp(S[i,j], max=1, min=1e-4)\r\n",
    "                    if j>=1:\r\n",
    "                        S[i,j] = torch.clamp(S[i,j], max=1-S[i,:j].sum()*0.5, min=1e-4)\r\n",
    "                    \r\n",
    "            S -= learning_rate * S.grad\r\n",
    "            # Manually zero the gradients after updating estimates\r\n",
    "            S.grad.zero_()\r\n",
    "            \r\n",
    "        r1 += rho * (torch.dot(torch.ones(4), u1.clone().detach()) - 1)\r\n",
    "        r0 += rho * (torch.dot(torch.ones(4), u0.clone().detach()) - 1)\r\n",
    "\r\n",
    "        if torch.any((lambdavec1.detach() + rho * (u1 - 1)) > 1):\r\n",
    "            lambdavec1.detach()[(lambdavec1.detach() + rho * (u1 - 1)) > 1] = ((lambdavec1.detach() * (u1 - 1))[(lambdavec1.detach() + rho * (u1 - 1)) > 1] \r\n",
    "                + (rho/2) * torch.norm(u1[(lambdavec1.detach() + rho * (u1 - 1)) > 1] - 1)**2)\r\n",
    "        elif torch.any((lambdavec1.detach() + rho * u1) < 1):\r\n",
    "            lambdavec1.detach()[(lambdavec1.detach() + rho * u1) < 1] = ((lambdavec1.detach() * u1)[(lambdavec1.detach() + rho * u1) < 1] \r\n",
    "                + (rho/2) * torch.norm(u1[(lambdavec1.detach() + rho * u1) < 1])**2)    \r\n",
    "        if torch.any((lambdavec0.detach() + rho * (u0 - 1)) > 1):\r\n",
    "            lambdavec0.detach()[(lambdavec0.detach() + rho * (u0 - 1)) > 1] = ((lambdavec0.detach() * (u0 - 1))[(lambdavec0.detach() + rho * (u0 - 1)) > 1] \r\n",
    "                + (rho/2) * torch.norm(u0[(lambdavec0.detach() + rho * (u0 - 1)) > 1] - 1)**2)\r\n",
    "        elif torch.any((lambdavec0.detach() + rho * u0) < 1):\r\n",
    "            lambdavec0.detach()[(lambdavec0.detach() + rho * u0) < 1] = ((lambdavec0.detach() * u0)[(lambdavec0.detach() + rho * u0) < 1] \r\n",
    "                + (rho/2) * torch.norm(u0[(lambdavec0.detach() + rho * u0) < 1])**2)    \r\n",
    "            \r\n",
    "        if t % 1000 == 999:\r\n",
    "            losslist = np.append(losslist, loss.item())\r\n",
    "            print(t, loss.item(), torch.mm(P1, torch.inverse(torch.cat([torch.ones(4,1),S], dim=1)))[0,:])\r\n",
    "            \r\n",
    "    S = torch.cat([torch.ones(4,1),S], dim=1)\r\n",
    "\r\n",
    "    loss_perm_list = []\r\n",
    "    u1_list = []\r\n",
    "    u0_list = []\r\n",
    "    loss_min = np.inf \r\n",
    "#     print(S)\r\n",
    "    for v in itertools.permutations([0,1,2,3], 4):\r\n",
    "        loss_perm, u1_cand, u0_cand,diag1_cand,diag0_cand = eval_perm1(S[v,:], Phat1, Phat0, Qhat1, Qhat0)\r\n",
    "        loss_perm += (r1 * (torch.dot(torch.ones(4), u1_cand) - 1) + rho/2  * (torch.dot(torch.ones(4), u1_cand) - 1)**2\r\n",
    "            + r0 * (torch.dot(torch.ones(4), u0_cand) - 1) + rho/2  * (torch.dot(torch.ones(4), u0_cand) - 1)**2\r\n",
    "            + torch.sum(f))\r\n",
    "        loss_perm_list.append(loss_perm)\r\n",
    "        u1_list.append(u1_cand)\r\n",
    "        u0_list.append(u0_cand)\r\n",
    "        if loss_perm < loss_min:\r\n",
    "            loss_min = loss_perm\r\n",
    "            S_hat = S[v,:]\r\n",
    "            u1_hat = torch.mm(P1, torch.inverse(S_hat))[0,:]\r\n",
    "            u0_hat = torch.mm(P0, torch.inverse(S_hat))[0,:]\r\n",
    "    u_hat = u1_hat * phat_x1 + u0_hat * phat_x0\r\n",
    "    return S.to('cpu').detach().numpy().copy(), S_hat.to('cpu').detach().numpy().copy(), u_hat.to('cpu').detach().numpy().copy(), u1_hat.to('cpu').detach().numpy().copy(), u0_hat.to('cpu').detach().numpy().copy(), loss_perm_list, loss_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phat1, Phat0, Qhat1, Qhat0 = calculate_PQ(X,Y,Z,W)\n",
    "\n",
    "if (np.linalg.cond(Phat1) >= 1/np.finfo(Phat1.dtype).eps) or (np.linalg.cond(Phat0) >= 1/np.finfo(Phat0.dtype).eps):\n",
    "    print(\"Phat1 or Phat0 is singular...\")\n",
    "\n",
    "if commutabilitycheck(Phat1,Phat0,Qhat1,Qhat0)>10000:\n",
    "    print(\"Non-commutative...\")\n",
    "    \n",
    "#S_cand, S_hat, u_hat, u1_hat, u0_hat, losslist, loss_min = optim(\n",
    "#    Phat1, Phat0, Qhat1, Qhat0, np.sum(X==1)/X.shape[0], np.sum(X==0)/X.shape[0], maxiter=10000, learning_rate=5e-4, rho=0.5, seed=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat:  0\n",
      "Commutability check: 27.4973\n",
      "999 8.021628379821777 tensor([0.2504, 0.4057, 0.1505, 0.1934], grad_fn=<SliceBackward>)\n",
      "1999 7.956346035003662 tensor([0.1704, 0.4473, 0.1539, 0.2284], grad_fn=<SliceBackward>)\n",
      "2999 7.909611225128174 tensor([0.1351, 0.4517, 0.0860, 0.3271], grad_fn=<SliceBackward>)\n",
      "3999 7.890269756317139 tensor([0.1403, 0.4459, 0.0680, 0.3458], grad_fn=<SliceBackward>)\n",
      "4999 7.888035297393799 tensor([0.1465, 0.4439, 0.0586, 0.3511], grad_fn=<SliceBackward>)\n",
      "5999 7.888330459594727 tensor([0.1496, 0.4431, 0.0542, 0.3531], grad_fn=<SliceBackward>)\n",
      "6999 7.888724327087402 tensor([0.1510, 0.4427, 0.0525, 0.3539], grad_fn=<SliceBackward>)\n",
      "7999 7.888942718505859 tensor([0.1515, 0.4426, 0.0517, 0.3542], grad_fn=<SliceBackward>)\n",
      "8999 7.889037609100342 tensor([0.1518, 0.4425, 0.0514, 0.3543], grad_fn=<SliceBackward>)\n",
      "9999 7.889087677001953 tensor([0.1519, 0.4425, 0.0513, 0.3544], grad_fn=<SliceBackward>)\n",
      "[0.31075752 0.31497458 0.20174386 0.17252417] tensor(38.2778, grad_fn=<AddBackward0>)\n",
      "Repeat:  1\n",
      "Commutability check: 27.4973\n",
      "999 7.559532642364502 tensor([0.3013, 0.1678, 0.2446, 0.2863], grad_fn=<SliceBackward>)\n",
      "1999 7.458018779754639 tensor([0.2544, 0.2459, 0.2081, 0.2917], grad_fn=<SliceBackward>)\n",
      "2999 7.439308166503906 tensor([0.2240, 0.2838, 0.1917, 0.3004], grad_fn=<SliceBackward>)\n",
      "3999 7.447173118591309 tensor([0.2017, 0.3040, 0.1882, 0.3061], grad_fn=<SliceBackward>)\n",
      "4999 7.450841903686523 tensor([0.1943, 0.3104, 0.1876, 0.3077], grad_fn=<SliceBackward>)\n",
      "5999 7.451493263244629 tensor([0.1930, 0.3115, 0.1876, 0.3079], grad_fn=<SliceBackward>)\n",
      "6999 7.451595306396484 tensor([0.1928, 0.3117, 0.1876, 0.3080], grad_fn=<SliceBackward>)\n",
      "7999 7.451600551605225 tensor([0.1927, 0.3117, 0.1876, 0.3080], grad_fn=<SliceBackward>)\n",
      "8999 7.4516119956970215 tensor([0.1927, 0.3117, 0.1876, 0.3080], grad_fn=<SliceBackward>)\n",
      "9999 7.4516096115112305 tensor([0.1927, 0.3117, 0.1876, 0.3080], grad_fn=<SliceBackward>)\n",
      "[0.5113312  0.1858095  0.17011535 0.1327437 ] tensor(38.3849, grad_fn=<AddBackward0>)\n",
      "Repeat:  2\n",
      "Commutability check: 27.4973\n",
      "999 7.621235370635986 tensor([0.1758, 0.3286, 0.2176, 0.2780], grad_fn=<SliceBackward>)\n",
      "1999 7.495129585266113 tensor([0.2458, 0.2687, 0.1943, 0.2912], grad_fn=<SliceBackward>)\n",
      "2999 7.475326061248779 tensor([0.2878, 0.2271, 0.1831, 0.3020], grad_fn=<SliceBackward>)\n",
      "3999 7.485789775848389 tensor([0.3037, 0.2051, 0.1838, 0.3074], grad_fn=<SliceBackward>)\n",
      "4999 7.488314628601074 tensor([0.3065, 0.2013, 0.1840, 0.3081], grad_fn=<SliceBackward>)\n",
      "5999 7.488648414611816 tensor([0.3069, 0.2008, 0.1841, 0.3082], grad_fn=<SliceBackward>)\n",
      "6999 7.488687992095947 tensor([0.3069, 0.2008, 0.1841, 0.3083], grad_fn=<SliceBackward>)\n",
      "7999 7.48868989944458 tensor([0.3069, 0.2008, 0.1841, 0.3083], grad_fn=<SliceBackward>)\n",
      "8999 7.488692760467529 tensor([0.3069, 0.2008, 0.1841, 0.3083], grad_fn=<SliceBackward>)\n",
      "9999 7.488692283630371 tensor([0.3069, 0.2008, 0.1841, 0.3083], grad_fn=<SliceBackward>)\n",
      "[0.5207676  0.15112185 0.18243565 0.14567491] tensor(38.5154, grad_fn=<AddBackward0>)\n",
      "Repeat:  3\n",
      "Commutability check: 27.4973\n",
      "999 8.03663444519043 tensor([0.2709, 0.3229, 0.1004, 0.3058], grad_fn=<SliceBackward>)\n",
      "1999 8.630191802978516 tensor([0.1770, 0.4329, 0.0389, 0.3513], grad_fn=<SliceBackward>)\n",
      "2999 7.8837456703186035 tensor([0.1501, 0.4412, 0.0595, 0.3492], grad_fn=<SliceBackward>)\n",
      "3999 7.8881425857543945 tensor([0.1496, 0.4428, 0.0550, 0.3526], grad_fn=<SliceBackward>)\n",
      "4999 7.88862419128418 tensor([0.1508, 0.4427, 0.0528, 0.3537], grad_fn=<SliceBackward>)\n",
      "5999 7.888885021209717 tensor([0.1514, 0.4426, 0.0519, 0.3541], grad_fn=<SliceBackward>)\n",
      "6999 7.88902473449707 tensor([0.1517, 0.4425, 0.0515, 0.3543], grad_fn=<SliceBackward>)\n",
      "7999 7.889078140258789 tensor([0.1519, 0.4425, 0.0513, 0.3544], grad_fn=<SliceBackward>)\n",
      "8999 7.889094829559326 tensor([0.1519, 0.4425, 0.0513, 0.3544], grad_fn=<SliceBackward>)\n",
      "9999 7.8891143798828125 tensor([0.1519, 0.4425, 0.0512, 0.3544], grad_fn=<SliceBackward>)\n",
      "[0.31073713 0.31500244 0.20172408 0.17253608] tensor(38.2778, grad_fn=<AddBackward0>)\n",
      "Repeat:  4\n",
      "Commutability check: 27.4973\n",
      "999 7.976285457611084 tensor([0.2510, 0.3841, 0.1985, 0.1664], grad_fn=<SliceBackward>)\n",
      "1999 7.880348205566406 tensor([0.1678, 0.4356, 0.2025, 0.1941], grad_fn=<SliceBackward>)\n",
      "2999 7.872150897979736 tensor([0.1390, 0.4568, 0.2048, 0.1995], grad_fn=<SliceBackward>)\n",
      "3999 7.872171401977539 tensor([0.1317, 0.4612, 0.2062, 0.2010], grad_fn=<SliceBackward>)\n",
      "4999 7.867551326751709 tensor([0.1305, 0.4629, 0.2052, 0.2014], grad_fn=<SliceBackward>)\n",
      "5999 7.866268157958984 tensor([0.1318, 0.4646, 0.2019, 0.2017], grad_fn=<SliceBackward>)\n",
      "6999 7.903380870819092 tensor([0.1272, 0.4604, 0.2104, 0.2020], grad_fn=<SliceBackward>)\n",
      "7999 7.845052719116211 tensor([0.1369, 0.4697, 0.1918, 0.2016], grad_fn=<SliceBackward>)\n",
      "8999 7.84640645980835 tensor([0.1340, 0.4676, 0.1970, 0.2014], grad_fn=<SliceBackward>)\n",
      "9999 7.897994041442871 tensor([0.1208, 0.4558, 0.2219, 0.2015], grad_fn=<SliceBackward>)\n",
      "[0.2693731  0.21889989 0.26677632 0.24495064] tensor(39.9640, grad_fn=<AddBackward0>)\n",
      "Repeat:  5\n",
      "Commutability check: 27.4973\n",
      "999 7.8399739265441895 tensor([0.3083, 0.3086, 0.3235, 0.0596], grad_fn=<SliceBackward>)\n",
      "1999 7.745306015014648 tensor([0.3313, 0.3163, 0.2586, 0.0938], grad_fn=<SliceBackward>)\n",
      "2999 7.597301483154297 tensor([0.2989, 0.3505, 0.2400, 0.1106], grad_fn=<SliceBackward>)\n",
      "3999 7.426608085632324 tensor([0.3521, 0.2751, 0.2374, 0.1354], grad_fn=<SliceBackward>)\n",
      "4999 8.004148483276367 tensor([0.4173, 0.2720, 0.0821, 0.2287], grad_fn=<SliceBackward>)\n",
      "5999 7.993714809417725 tensor([0.3835, 0.1279, 0.1453, 0.3432], grad_fn=<SliceBackward>)\n",
      "6999 7.87586784362793 tensor([0.4232, 0.1634, 0.0818, 0.3315], grad_fn=<SliceBackward>)\n",
      "7999 7.880339622497559 tensor([0.4245, 0.1646, 0.0844, 0.3265], grad_fn=<SliceBackward>)\n",
      "8999 7.879042148590088 tensor([0.4302, 0.1664, 0.0805, 0.3229], grad_fn=<SliceBackward>)\n",
      "9999 8.254945755004883 tensor([0.3477, 0.1155, 0.2488, 0.2879], grad_fn=<SliceBackward>)\n",
      "[0.30831897 0.2657145  0.29589126 0.1300753 ] tensor(39.0007, grad_fn=<AddBackward0>)\n",
      "Repeat:  6\n",
      "Commutability check: 27.4973\n",
      "999 7.632386207580566 tensor([0.2850, 0.4000, 0.0722, 0.2427], grad_fn=<SliceBackward>)\n",
      "1999 7.781488418579102 tensor([0.1754, 0.4414, 0.0800, 0.3032], grad_fn=<SliceBackward>)\n",
      "2999 7.702639579772949 tensor([0.1454, 0.4587, 0.0530, 0.3429], grad_fn=<SliceBackward>)\n",
      "3999 7.67901611328125 tensor([0.1352, 0.4638, 0.0484, 0.3526], grad_fn=<SliceBackward>)\n",
      "4999 7.674455642700195 tensor([0.1328, 0.4672, 0.0470, 0.3531], grad_fn=<SliceBackward>)\n",
      "5999 7.673923492431641 tensor([0.1321, 0.4688, 0.0464, 0.3526], grad_fn=<SliceBackward>)\n",
      "6999 7.673996925354004 tensor([0.1319, 0.4696, 0.0462, 0.3523], grad_fn=<SliceBackward>)\n",
      "7999 7.674090385437012 tensor([0.1319, 0.4699, 0.0460, 0.3521], grad_fn=<SliceBackward>)\n",
      "8999 7.674142837524414 tensor([0.1319, 0.4701, 0.0460, 0.3521], grad_fn=<SliceBackward>)\n",
      "9999 7.6741743087768555 tensor([0.1319, 0.4701, 0.0460, 0.3520], grad_fn=<SliceBackward>)\n",
      "[0.27652445 0.38254195 0.17390542 0.16702831] tensor(37.8416, grad_fn=<AddBackward0>)\n",
      "Repeat:  7\n",
      "Commutability check: 27.4973\n",
      "999 8.288416862487793 tensor([0.2201, 0.2916, 0.2647, 0.2236], grad_fn=<SliceBackward>)\n",
      "1999 8.158355712890625 tensor([0.1732, 0.3255, 0.2784, 0.2229], grad_fn=<SliceBackward>)\n",
      "2999 7.897059440612793 tensor([0.0743, 0.3028, 0.2795, 0.3434], grad_fn=<SliceBackward>)\n",
      "3999 7.883599281311035 tensor([0.0566, 0.3188, 0.2818, 0.3428], grad_fn=<SliceBackward>)\n",
      "4999 7.882257461547852 tensor([0.0578, 0.3196, 0.2810, 0.3416], grad_fn=<SliceBackward>)\n",
      "5999 7.882001876831055 tensor([0.0588, 0.3194, 0.2807, 0.3411], grad_fn=<SliceBackward>)\n",
      "6999 7.881931781768799 tensor([0.0591, 0.3193, 0.2807, 0.3409], grad_fn=<SliceBackward>)\n",
      "7999 7.881917476654053 tensor([0.0593, 0.3192, 0.2806, 0.3409], grad_fn=<SliceBackward>)\n",
      "8999 7.881923675537109 tensor([0.0593, 0.3192, 0.2806, 0.3409], grad_fn=<SliceBackward>)\n",
      "9999 7.881910800933838 tensor([0.0593, 0.3192, 0.2806, 0.3409], grad_fn=<SliceBackward>)\n",
      "[0.2897645  0.29676795 0.23646726 0.17700052] tensor(38.0452, grad_fn=<AddBackward0>)\n",
      "Repeat:  8\n",
      "Commutability check: 27.4973\n",
      "999 8.285224914550781 tensor([ 0.6818, -0.0013,  0.1799,  0.1396], grad_fn=<SliceBackward>)\n",
      "1999 8.267056465148926 tensor([0.6546, 0.1058, 0.1857, 0.0539], grad_fn=<SliceBackward>)\n",
      "2999 7.697159290313721 tensor([0.6769, 0.1904, 0.1283, 0.0044], grad_fn=<SliceBackward>)\n",
      "3999 7.523789405822754 tensor([0.6649, 0.2836, 0.0443, 0.0072], grad_fn=<SliceBackward>)\n",
      "4999 7.521613121032715 tensor([0.6673, 0.2843, 0.0425, 0.0059], grad_fn=<SliceBackward>)\n",
      "5999 9.790506362915039 tensor([0.5842, 0.1889, 0.2069, 0.0200], grad_fn=<SliceBackward>)\n",
      "6999 7.533630847930908 tensor([0.6513, 0.2817, 0.0547, 0.0123], grad_fn=<SliceBackward>)\n",
      "7999 7.555545806884766 tensor([0.6299, 0.2694, 0.0889, 0.0118], grad_fn=<SliceBackward>)\n",
      "8999 7.554834365844727 tensor([0.6293, 0.2725, 0.0843, 0.0138], grad_fn=<SliceBackward>)\n",
      "9999 7.5237603187561035 tensor([0.6598, 0.2875, 0.0446, 0.0081], grad_fn=<SliceBackward>)\n",
      "[0.31305093 0.24317181 0.20889415 0.23488303] tensor(39.1121, grad_fn=<AddBackward0>)\n",
      "Repeat:  9\n",
      "Commutability check: 27.4973\n",
      "999 7.5413689613342285 tensor([0.3141, 0.2134, 0.1935, 0.2790], grad_fn=<SliceBackward>)\n",
      "1999 7.44526481628418 tensor([0.2487, 0.2599, 0.1972, 0.2942], grad_fn=<SliceBackward>)\n",
      "2999 7.438465118408203 tensor([0.2160, 0.2924, 0.1889, 0.3028], grad_fn=<SliceBackward>)\n",
      "3999 7.448330879211426 tensor([0.1981, 0.3072, 0.1878, 0.3069], grad_fn=<SliceBackward>)\n",
      "4999 7.45111083984375 tensor([0.1936, 0.3110, 0.1876, 0.3078], grad_fn=<SliceBackward>)\n",
      "5999 7.451542377471924 tensor([0.1929, 0.3116, 0.1876, 0.3080], grad_fn=<SliceBackward>)\n",
      "6999 7.451601028442383 tensor([0.1928, 0.3117, 0.1876, 0.3080], grad_fn=<SliceBackward>)\n",
      "7999 7.451605319976807 tensor([0.1927, 0.3117, 0.1876, 0.3080], grad_fn=<SliceBackward>)\n",
      "8999 7.451611518859863 tensor([0.1927, 0.3117, 0.1876, 0.3080], grad_fn=<SliceBackward>)\n",
      "9999 7.4516096115112305 tensor([0.1927, 0.3117, 0.1876, 0.3080], grad_fn=<SliceBackward>)\n",
      "[0.5113313  0.1858099  0.17011483 0.13274398] tensor(38.3849, grad_fn=<AddBackward0>)\n",
      "[0.27652445 0.38254195 0.17390542 0.16702831] tensor(37.8416)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2022)\n",
    "S_cand_list = []\n",
    "S_hat_list = []\n",
    "u_hat_list = []\n",
    "u1_hat_list = []\n",
    "u0_hat_list = []\n",
    "losslist_list = []\n",
    "loss_min_list = []\n",
    "# Take minimum loss while repeating 5 times\n",
    "for k in range(10):\n",
    "    print(\"Repeat: \",k)\n",
    "    S_cand, S_hat, u_hat, u1_hat, u0_hat, losslist, loss_min = optim(\n",
    "            Phat1, Phat0, Qhat1, Qhat0, np.sum(X==1)/X.shape[0], np.sum(X==0)/X.shape[0], maxiter=10000, learning_rate=5e-4, rho=0.5)\n",
    "    print(u_hat,loss_min)\n",
    "    cnt = 0 # counter for re-initialization\n",
    "    while any(u_hat<0) | any(u_hat>1):\n",
    "        cnt += 1\n",
    "        print(\"Re-initialization...\")        \n",
    "        try:\n",
    "            S_cand, S_hat, u_hat, u1_hat, u0_hat, losslist, loss_min = optim(\n",
    "                    Phat1, Phat0, Qhat1, Qhat0, np.sum(X==1)/X.shape[0], np.sum(X==0)/X.shape[0], maxiter=10000, learning_rate=5e-4, rho=0.5)\n",
    "        except RuntimeError: # if S is singular\n",
    "            print('Error')\n",
    "            continue            \n",
    "        print(u_hat,loss_min)\n",
    "\n",
    "    S_cand_list.append(S_cand)\n",
    "    S_hat_list.append(S_hat)\n",
    "    u_hat_list.append(u_hat)\n",
    "    u1_hat_list.append(u1_hat)\n",
    "    u0_hat_list.append(u0_hat)\n",
    "    losslist_list.append(losslist)\n",
    "    loss_min_list.append(loss_min.detach())\n",
    "\n",
    "minidx = np.argmin(loss_min_list)\n",
    "u_hat = u_hat_list[minidx]\n",
    "print(u_hat,loss_min_list[minidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.277 0.383 0.174 0.167]\n",
      "0.209\n",
      "0.383\n"
     ]
    }
   ],
   "source": [
    "print(u_hat.round(3))\n",
    "print((u_hat[1]-u_hat[2]).round(3))\n",
    "print((u_hat[1]).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(u_sim100_1000_type1).boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>,\n",
       "        <AxesSubplot:title={'center':'1'}>],\n",
       "       [<AxesSubplot:title={'center':'2'}>,\n",
       "        <AxesSubplot:title={'center':'3'}>]], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(u_sim100_1000_type1).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPS1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>treat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>married</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>re74</th>\n",
       "      <th>re75</th>\n",
       "      <th>re78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9930.045898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3595.894043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24909.449219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7506.145996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.789886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>CPS3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10150.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>CPS3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19464.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>CPS3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>CPS3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.671295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>CPS3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1495.458984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  data_id  treat   age  education  black  hispanic  married  \\\n",
       "0    Dehejia-Wahba Sample    1.0  37.0       11.0    1.0       0.0      1.0   \n",
       "1    Dehejia-Wahba Sample    1.0  22.0        9.0    0.0       1.0      0.0   \n",
       "2    Dehejia-Wahba Sample    1.0  30.0       12.0    1.0       0.0      0.0   \n",
       "3    Dehejia-Wahba Sample    1.0  27.0       11.0    1.0       0.0      0.0   \n",
       "4    Dehejia-Wahba Sample    1.0  33.0        8.0    1.0       0.0      0.0   \n",
       "..                    ...    ...   ...        ...    ...       ...      ...   \n",
       "609                  CPS3    0.0  18.0       11.0    0.0       0.0      0.0   \n",
       "610                  CPS3    0.0  24.0        1.0    0.0       1.0      1.0   \n",
       "611                  CPS3    0.0  21.0       18.0    0.0       0.0      0.0   \n",
       "612                  CPS3    0.0  32.0        5.0    1.0       0.0      1.0   \n",
       "613                  CPS3    0.0  16.0        9.0    0.0       0.0      0.0   \n",
       "\n",
       "     nodegree  re74  re75          re78  \n",
       "0         1.0   0.0   0.0   9930.045898  \n",
       "1         1.0   0.0   0.0   3595.894043  \n",
       "2         0.0   0.0   0.0  24909.449219  \n",
       "3         1.0   0.0   0.0   7506.145996  \n",
       "4         1.0   0.0   0.0    289.789886  \n",
       "..        ...   ...   ...           ...  \n",
       "609       1.0   0.0   0.0  10150.500000  \n",
       "610       1.0   0.0   0.0  19464.609375  \n",
       "611       0.0   0.0   0.0      0.000000  \n",
       "612       1.0   0.0   0.0    187.671295  \n",
       "613       1.0   0.0   0.0   1495.458984  \n",
       "\n",
       "[614 rows x 11 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_nsw[df_nsw[\"treat\"] == 1], df_cps3], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[\"treat\"].values.tolist())\n",
    "Yflag = (df[\"re78\"] > df[\"re75\"])\n",
    "Y = np.array((Yflag*1).values.tolist())\n",
    "# missing re74 or no degree\n",
    "Z = np.array([0] * df.shape[0])\n",
    "for i in range(df.shape[0]):\n",
    "    if ((df[\"re75\"][i] == 0) and (df[\"married\"][i] == 0)):\n",
    "        Z[i] = 3\n",
    "    elif ((df[\"re75\"][i] == 0) and (df[\"married\"][i] > 0)):\n",
    "        Z[i] = 2\n",
    "    elif ((df[\"re75\"][i] > 0) and (df[\"married\"][i] == 0)):\n",
    "        Z[i] = 1\n",
    "    elif ((df[\"re75\"][i] > 0) and (df[\"married\"][i] > 0)):\n",
    "        Z[i] = 0\n",
    "        \n",
    "# Strata by age\n",
    "W = np.array([0] * df.shape[0])\n",
    "for i in range(df.shape[0]):\n",
    "    if df[\"age\"][i] >= df[\"age\"].quantile(0.9):\n",
    "        W[i] = 3\n",
    "    elif (df[\"age\"][i] >= df[\"age\"].quantile(0.7)) and (df[\"age\"][i] < df[\"age\"].quantile(0.9)):\n",
    "        W[i] = 2\n",
    "    elif (df[\"age\"][i] >= df[\"age\"].quantile(0.25)) and (df[\"age\"][i] < df[\"age\"].quantile(0.7)):\n",
    "        W[i] = 1\n",
    "    elif (df[\"age\"][i] >= df[\"age\"].quantile(0)) and (df[\"age\"][i] < df[\"age\"].quantile(0.25)):\n",
    "        W[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating P1, P0, Q1, and Q0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phat1, Phat0, Qhat1, Qhat0 = calculate_PQ(X,Y,Z,W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating joint distribution of potential outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commutability check: 37.335205\n",
      "999 8.00411605834961 tensor([ 0.0255,  1.2496, -0.2014, -0.0738], grad_fn=<SliceBackward>)\n",
      "1999 7.902761459350586 tensor([ 0.0073,  1.2075, -0.1458, -0.0690], grad_fn=<SliceBackward>)\n",
      "2999 7.900548458099365 tensor([ 0.0175,  1.1953, -0.1343, -0.0784], grad_fn=<SliceBackward>)\n",
      "3999 7.914982318878174 tensor([-0.0026,  1.1496, -0.1209, -0.0261], grad_fn=<SliceBackward>)\n",
      "4999 7.921797275543213 tensor([-0.0253,  1.1611, -0.1238, -0.0119], grad_fn=<SliceBackward>)\n",
      "5999 8.023785591125488 tensor([-0.0179,  1.2408, -0.1289, -0.0939], grad_fn=<SliceBackward>)\n",
      "6999 7.92572021484375 tensor([-0.0057,  1.1513, -0.1100, -0.0356], grad_fn=<SliceBackward>)\n",
      "7999 7.899347305297852 tensor([-0.0181,  1.1191, -0.1069,  0.0059], grad_fn=<SliceBackward>)\n",
      "8999 8.00847339630127 tensor([-0.0376,  1.2226, -0.1189, -0.0662], grad_fn=<SliceBackward>)\n",
      "9999 7.95179557800293 tensor([-0.0101,  1.1691, -0.1026, -0.0565], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "Phat1, Phat0, Qhat1, Qhat0 = calculate_PQ(X,Y,Z,W)\n",
    "\n",
    "if (np.linalg.cond(Phat1) >= 1/np.finfo(Phat1.dtype).eps) or (np.linalg.cond(Phat0) >= 1/np.finfo(Phat0.dtype).eps):\n",
    "    print(\"Phat1 or Phat0 is singular...\")\n",
    "\n",
    "if commutabilitycheck(Phat1,Phat0,Qhat1,Qhat0)>10000:\n",
    "    print(\"Non-commutative...\")\n",
    "    \n",
    "S_cand, S_hat, u_hat, u1_hat, u0_hat, losslist, loss_min = optim(\n",
    "    Phat1, Phat0, Qhat1, Qhat0, np.sum(X==1)/X.shape[0], np.sum(X==0)/X.shape[0], maxiter=10000, learning_rate=5e-4, rho=0.5, seed=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
